import boto3
import json
from app.core.config import settings
from typing import Optional, List, Dict, Any
import xml.etree.ElementTree as ET
import re
from app.schemas.recipe import ChatPreviewInfo, ChatResponse
from langchain_aws import AmazonKnowledgeBasesRetriever, ChatBedrock
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.runnables import RunnableSequence # ì²´ì¸ íƒ€ì…
from langchain_core.messages import HumanMessage, AIMessage # ë©”ì‹œì§€ íƒ€ì…

# ì„¤ì • íŒŒì¼ì—ì„œ AWS ì •ë³´ ë¡œë“œ
try:
    llm = ChatBedrock(
        model_id=settings.BEDROCK_MODEL_ID,
        region_name=settings.AWS_DEFAULT_REGION,
        model_kwargs={"max_tokens": 4096}, # ì¶©ë¶„íˆ ë„‰ë„‰í•˜ê²Œ ì„¤ì •
        streaming=True, # ìŠ¤íŠ¸ë¦¬ë° í™œì„±í™”
    )
    MODEL_ID = settings.BEDROCK_MODEL_ID
    
    KNOWLEDGE_BASE_ID = settings.KNOWLEDGE_BASE_ID
    if KNOWLEDGE_BASE_ID:
        retriever = AmazonKnowledgeBasesRetriever(
            knowledge_base_id=KNOWLEDGE_BASE_ID,
            retrieval_config={"vectorSearchConfiguration": {"numberOfResults": 5}},
            region_name=settings.AWS_DEFAULT_REGION,
        )
    else:
        retriever = None

except Exception as e:
    print(f"[Bedrock_Service] LangChain LLM ë˜ëŠ” Retriever ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    bedrock_runtime = None
    llm = None # ğŸ”´ LLM ê°ì²´ ì‹¤íŒ¨ ì‹œ None í• ë‹¹
    retriever = None # ì‹¤íŒ¨ ì‹œ retrieverë„ None
    MODEL_ID = None
    KNOWLEDGE_BASE_ID = None

def format_docs(docs):
    """ê²€ìƒ‰ëœ ë¬¸ì„œë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜ (ì°¸ê³  ì½”ë“œì—ì„œ ê°€ì ¸ì˜´)"""
    if not docs:
        print("âš ï¸ [KB] ê²€ìƒ‰ëœ ë¬¸ì„œ ì—†ìŒ")
        return "" # KB ê²€ìƒ‰ ê²°ê³¼ ì—†ìœ¼ë©´ ë¹ˆ ë¬¸ìì—´ ë°˜í™˜
    # ... (ë¡œì§ ìƒëµ, ê¸°ì¡´ê³¼ ë™ì¼) ...
    formatted = []
    for idx, doc in enumerate(docs):
        content = None
        if isinstance(doc, dict):
            content = (
                doc.get("content")
                or doc.get("page_content")
                or doc.get("text")
                or doc.get("excerpt")
            )
            if isinstance(content, dict):
                content = content.get("text") or json.dumps(content, ensure_ascii=False)
        else:
            content = getattr(doc, "page_content", None)
        if content:
            if isinstance(content, str):
                content_str = content.strip()
            else:
                content_str = str(content)
            if content_str:
                formatted.append(content_str)
    result = ("\n\n---\n\n".join(formatted) if formatted else "")
    print(f"âœ… [KB] {len(formatted)}ê°œ ë¬¸ì„œ í¬ë§· ì™„ë£Œ (ì´ {len(result)}ì)")
    return result


# --- [_get_system_prompt] í•¨ìˆ˜ëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€ ---
def _get_system_prompt(language: str) -> str:
    # ... (ë¡œì§ ìƒëµ, ê¸°ì¡´ê³¼ ë™ì¼) ...
    if language.lower() == "eng":
        return """You are "Chef Kim", a professional chef who introduces K-Food to foreigners.
... (ì¤‘ëµ) ...
"""
    else:  # í•œêµ­ì–´ (ê¸°ë³¸ê°’)
        return """ë‹¹ì‹ ì€ "ì…°í”„ ê¹€(Chef Kim)"ì´ë¼ëŠ” ì´ë¦„ì„ ê°€ì§„, ì™¸êµ­ì¸ì—ê²Œ **K-Food(í•œì‹)**ë¥¼ ì•Œë ¤ì£¼ëŠ” ì „ë¬¸ ìš”ë¦¬ì‚¬ì…ë‹ˆë‹¤.
... (ì¤‘ëµ) ...
"""

# --- [create_bedrock_payload í•¨ìˆ˜ë¥¼ LangChain Helperë¡œ ëŒ€ì²´] ---

def create_user_input_with_context(language: str, base_query: str, context_str: str) -> str:
    """KB ì»¨í…ìŠ¤íŠ¸ê°€ í¬í•¨ëœ ìµœì¢… ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ìƒì„±"""
    if context_str:
        if language.lower() == "eng":
            return f"""Here is some context. Use this to create the recipe:
<context>{context_str}</context>
User Request: {base_query}"""
        else:
            return f"""KB ì°¸ê³  ìë£Œì…ë‹ˆë‹¤:
<context>{context_str}</context>
ì‚¬ìš©ì ìš”ì²­: {base_query}"""
    return base_query


def get_chat_chain(language: str) -> RunnableSequence:
    """
    LangChain Runnable ì²´ì¸ì„ ìƒì„± (LangChain í†µí•©ì˜ í•µì‹¬)
    KB ê²€ìƒ‰ ê²°ê³¼ëŠ” router.pyì—ì„œ context_strë¡œ ì´ë¯¸ ì²˜ë¦¬ë˜ì—ˆìœ¼ë¯€ë¡œ,
    ì´ ì²´ì¸ì€ ë‹¨ìˆœí•˜ê²Œ í”„ë¡¬í”„íŠ¸ì™€ LLMì„ ê²°í•©í•©ë‹ˆë‹¤.
    """
    
    # LangChain ChatPromptTemplate ì •ì˜
    prompt = ChatPromptTemplate.from_messages(
        [
            ("system", _get_system_prompt(language)), # ê¸°ì¡´ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì¬í™œìš©
            MessagesPlaceholder(variable_name="chat_history"), # Chat Historyë¥¼ ìœ„í•œ í”Œë ˆì´ìŠ¤í™€ë”
            ("human", "{input}"),
        ]
    )
    
    # ğŸ”´ LangChain ì²´ì¸ êµ¬ì„±
    return (
        {
            # chat_historyì™€ inputì€ routerì—ì„œ LangChain í˜•ì‹ì— ë§ê²Œ payloadë¡œ ì „ë‹¬
            "chat_history": lambda x: x["chat_history"],
            "input": lambda x: x["input"],
        }
        | prompt
        | llm # ğŸ”´ ì „ì—­ llm ê°ì²´ ì‚¬ìš©
    )